{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2IETyPtQCdO",
        "outputId": "97aec673-865b-4a6f-d55f-c6e0cc71eefd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import copy\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye7eyUGTMiAq",
        "outputId": "d8a55284-c848-47c6-cd80-769e242ba6ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XiR7bSQQr71Q"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic Block for resnet 18 and resnet 34\n",
        "    REF: https://github.com/weiaicunzai/pytorch-cifar100/blob/master/models/resnet.py\n",
        "    https://love2017.asia/2021/08/15/pytorchtrain8/\n",
        "    https://zhuanlan.zhihu.com/p/54289848\n",
        "    out_dim = (in_dim + 2p - k)/s + 1\n",
        "    p: padding size\n",
        "    s = stride\n",
        "    k = kernel size\n",
        "    \"\"\"\n",
        "\n",
        "    # BasicBlock and BottleNeck block\n",
        "    # have different output size\n",
        "    #we use class attribute expansion to distinct\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        # residual function\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * self.expansion)\n",
        "        )\n",
        "\n",
        "        # shortcut\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        # the shortcut output dimension is not the same with residual function\n",
        "        # use 1*1 convolution to match the dimension\n",
        "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JZ_RUGnttCZi"
      },
      "outputs": [],
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual block for resnet over 50 layers\n",
        "    BottleNeck apply 1x1 kernel, greatly reduce the calculation amount\n",
        "    \"\"\"\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False), # 1x1 kernel，reduce dimension\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False), # raise dim\n",
        "            nn.BatchNorm2d(out_channels * self.expansion),\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * self.expansion, stride=stride, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sIjpsompIntc"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, num_block, num_classes=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = 64\n",
        "        # set the first conv bias = FALSE\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True))\n",
        "        # we use a different inputsize than the original paper\n",
        "        # so conv2_x's stride is 1\n",
        "        self.conv2_x = self._make_layer(block, 32, num_block[0], 1)\n",
        "        # use stride = 2 to down-sample\n",
        "        self.conv3_x = self._make_layer(block, 64, num_block[1], 2)\n",
        "        self.conv4_x = self._make_layer(block, 128, num_block[2], 2)\n",
        "        self.conv5_x = self._make_layer(block, 256, num_block[3], 2)\n",
        "\n",
        "        # mod\n",
        "        # self.dpout = nn.Dropout(0.5)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        \"\"\"\n",
        "        make resnet layers(by layer i didnt mean this 'layer' was the\n",
        "        same as a neuron netowork layer, ex. conv layer), one layer may\n",
        "        contain more than one residual block\n",
        "        Args:\n",
        "            block: block type, basic block or bottle neck block\n",
        "            out_channels: output depth channel number of this layer\n",
        "            num_blocks: how many blocks per layer\n",
        "            stride: the stride of the first block of this layer\n",
        "        Return:\n",
        "            return a resnet layer\n",
        "        \"\"\"\n",
        "\n",
        "        # we have num_block blocks per layer, the first block\n",
        "        # could be 1 or 2, other blocks would always be 1\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.conv2_x(output)\n",
        "        output = self.conv3_x(output)\n",
        "        output = self.conv4_x(output)\n",
        "        output = self.conv5_x(output)\n",
        "\n",
        "        # mod\n",
        "        # output = self.dpout(output)\n",
        "\n",
        "        output = self.avg_pool(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WsY_0CgaLCgD"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class ST_ResNet(nn.Module):\n",
        "    loc_size = 4 * 4 * 10\n",
        "\n",
        "    def __init__(self, block, num_block, num_classes=100):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        # Spatial transformer localization-network\n",
        "        self.localization = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, kernel_size=7),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(8, 10, kernel_size=5),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        # Regressor for the 3 * 2 affine matrix\n",
        "        self.fc_loc = nn.Sequential(\n",
        "            nn.Linear(self.loc_size, 32),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(32, 3 * 2)\n",
        "        )\n",
        "\n",
        "        # Initialize the weights/bias with identity transformation\n",
        "        self.fc_loc[2].weight.data.zero_()\n",
        "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
        "        self.ST_Norm = nn.BatchNorm2d(3)\n",
        "\n",
        "\n",
        "        self.in_channels = 64\n",
        "        # set the first conv bias = FALSE\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True))\n",
        "        # we use a different inputsize than the original paper\n",
        "        # so conv2_x's stride is 1\n",
        "        self.conv2_x = self._make_layer(block, 32, num_block[0], 1)\n",
        "        # use stride = 2 to down-sample\n",
        "        self.conv3_x = self._make_layer(block, 64, num_block[1], 2)\n",
        "        self.dpout1 = nn.Dropout(0.3)\n",
        "        self.conv4_x = self._make_layer(block, 128, num_block[2], 2)\n",
        "        self.dpout2 = nn.Dropout(0.5)\n",
        "        self.conv5_x = self._make_layer(block, 256, num_block[3], 2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        \"\"\"\n",
        "        make resnet layers(by layer i didnt mean this 'layer' was the\n",
        "        same as a neuron netowork layer, ex. conv layer), one layer may\n",
        "        contain more than one residual block\n",
        "        Args:\n",
        "            block: block type, basic block or bottle neck block\n",
        "            out_channels: output depth channel number of this layer\n",
        "            num_blocks: how many blocks per layer\n",
        "            stride: the stride of the first block of this layer\n",
        "        Return:\n",
        "            return a resnet layer\n",
        "        \"\"\"\n",
        "\n",
        "        # we have num_block blocks per layer, the first block\n",
        "        # could be 1 or 2, other blocks would always be 1\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    \n",
        "    def stn(self, x):\n",
        "        xs = self.localization(x)\n",
        "        xs = xs.view(-1, self.loc_size)\n",
        "        theta = self.fc_loc(xs)\n",
        "        theta = theta.view(-1, 2, 3)\n",
        "\n",
        "        grid = F.affine_grid(theta, x.size())\n",
        "        x = F.grid_sample(x, grid)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # transform the input\n",
        "        #x = self.stn(x)\n",
        "        #x = self.ST_Norm(x)\n",
        "\n",
        "        output = self.conv1(x)\n",
        "        output = self.conv2_x(output)\n",
        "        output = self.conv3_x(output)\n",
        "        output = self.dpout1(output)\n",
        "        output = self.conv4_x(output)\n",
        "        output = self.dpout2(output)\n",
        "        output = self.conv5_x(output)\n",
        "        output = self.avg_pool(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "egIOiS70KgNP"
      },
      "outputs": [],
      "source": [
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "def ResNet50():\n",
        "    return ResNet(BottleNeck, [3, 4, 6, 3])\n",
        "def ResNet_Adjust():\n",
        "    return ResNet(BottleNeck, [1, 2, 3, 3])\n",
        "def ST_ResNetv1():\n",
        "    return ST_ResNet(BottleNeck, [1, 2, 3, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AjzRK2-aKiVD"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3VYW6VkSMBy",
        "outputId": "3deddad3-1600-4c0e-f587-5c7a7ac56327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data, applying data augmentation strategy\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "print('==> Preparing data, applying data augmentation strategy')\n",
        "ROOT = '.data'\n",
        "# need to calculate train mean and std first\n",
        "train_data = torchvision.datasets.CIFAR10(root = ROOT, \n",
        "                              train = True, \n",
        "                              download = True)\n",
        "means = train_data.data.mean(axis = (0,1,2)) / 255\n",
        "stds = train_data.data.std(axis = (0,1,2)) / 255\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                           transforms.RandomRotation(5),\n",
        "                           transforms.RandomHorizontalFlip(0.5),\n",
        "                           transforms.RandomCrop(32, padding = 2),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = means, \n",
        "                                                std = stds)\n",
        "                       ])\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = means, \n",
        "                                                std = stds)\n",
        "                       ])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(ROOT, \n",
        "                              train = True, \n",
        "                              download = True, \n",
        "                              transform = train_transforms)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(ROOT, \n",
        "                             train = False, \n",
        "                             download = True, \n",
        "                             transform = test_transforms)\n",
        "\n",
        "# split out validation data\n",
        "VALID_RATIO = 0.85\n",
        "\n",
        "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
        "n_valid_examples = len(train_data) - n_train_examples\n",
        "\n",
        "train_data, valid_data = torch.utils.data.random_split(train_data, \n",
        "                                           [n_train_examples, n_valid_examples])\n",
        "\n",
        "valid_data = copy.deepcopy(valid_data)\n",
        "valid_data.dataset.transform = test_transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GUYKL77wMTS1"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "        train_data, \n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=True,\n",
        "        batch_size=BATCH_SIZE)\n",
        "\n",
        "validloader = torch.utils.data.DataLoader(\n",
        "        valid_data, \n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=True,\n",
        "        batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "        test_data,\n",
        "        shuffle=True,\n",
        "        pin_memory=True,\n",
        "        num_workers=2,\n",
        "        drop_last=True,\n",
        "        batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2tQi77qzMpy0"
      },
      "outputs": [],
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWHtG-QeMslN",
        "outputId": "fc6b6ccf-acc3-4a1e-c44a-0597328076d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "print('==> Building model..')\n",
        "#net = ResNet_Adjust()\n",
        "net = ST_ResNetv1()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdQ8AVVnM5To",
        "outputId": "54e4d838-36e0-4c7b-a946-91799133851e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Layer (type:depth-idx)                        Param #\n",
            "======================================================================\n",
            "DataParallel                                  --\n",
            "├─ST_ResNet: 1-1                              --\n",
            "│    └─Sequential: 2-1                        --\n",
            "│    │    └─Conv2d: 3-1                       1,184\n",
            "│    │    └─MaxPool2d: 3-2                    --\n",
            "│    │    └─ReLU: 3-3                         --\n",
            "│    │    └─Conv2d: 3-4                       2,010\n",
            "│    │    └─MaxPool2d: 3-5                    --\n",
            "│    │    └─ReLU: 3-6                         --\n",
            "│    └─Sequential: 2-2                        --\n",
            "│    │    └─Linear: 3-7                       5,152\n",
            "│    │    └─ReLU: 3-8                         --\n",
            "│    │    └─Linear: 3-9                       198\n",
            "│    └─BatchNorm2d: 2-3                       6\n",
            "│    └─Sequential: 2-4                        --\n",
            "│    │    └─Conv2d: 3-10                      1,728\n",
            "│    │    └─BatchNorm2d: 3-11                 128\n",
            "│    │    └─ReLU: 3-12                        --\n",
            "│    └─Sequential: 2-5                        --\n",
            "│    │    └─BottleNeck: 3-13                  24,192\n",
            "│    └─Sequential: 2-6                        --\n",
            "│    │    └─BottleNeck: 3-14                  95,488\n",
            "│    │    └─BottleNeck: 3-15                  70,400\n",
            "│    └─Dropout: 2-7                           --\n",
            "│    └─Sequential: 2-8                        --\n",
            "│    │    └─BottleNeck: 3-16                  379,392\n",
            "│    │    └─BottleNeck: 3-17                  280,064\n",
            "│    │    └─BottleNeck: 3-18                  280,064\n",
            "│    └─Dropout: 2-9                           --\n",
            "│    └─Sequential: 2-10                       --\n",
            "│    │    └─BottleNeck: 3-19                  1,512,448\n",
            "│    │    └─BottleNeck: 3-20                  1,117,184\n",
            "│    │    └─BottleNeck: 3-21                  1,117,184\n",
            "│    └─AdaptiveAvgPool2d: 2-11                --\n",
            "│    └─Linear: 2-12                           102,500\n",
            "======================================================================\n",
            "Total params: 4,989,322\n",
            "Trainable params: 4,989,322\n",
            "Non-trainable params: 0\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(net))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nrbAzC8IZkgM"
      },
      "outputs": [],
      "source": [
        "class Optimization:\n",
        "  def __init__(self, model, loss_fn, optimizer, patience, EPOCH):\n",
        "    self.model = model\n",
        "    self.loss_fn = loss_fn\n",
        "    self.optimizer = optimizer\n",
        "    self.patience = patience\n",
        "    self.epochs = EPOCH\n",
        "    self.train_losses = []\n",
        "    self.val_losses = []\n",
        "    self.train_accuracy = []\n",
        "    self.val_accuracy = []\n",
        "\n",
        "\n",
        "  def train(self, train_loader, val_loader):\n",
        "    # apply early stopping\n",
        "    trigger_time = 0\n",
        "\n",
        "    for epoch in range(1, self.epochs + 1):\n",
        "      self.model.train()\n",
        "      total = 0\n",
        "      correct = 0\n",
        "      train_loss = 0\n",
        "      for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          outputs = net(inputs)\n",
        "          loss = criterion(outputs, targets)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # # L1 regularization\n",
        "          # l1_lambda = 0.001\n",
        "          # l1_norm = sum(torch.linalg.norm(p, 1) for p in self.model.parameters())\n",
        "          # l1 = l1_lambda * l1_norm\n",
        "          # train_loss += (loss.item() + l1)\n",
        "\n",
        "          train_loss += loss.item()\n",
        "          _, predicted = outputs.max(1)\n",
        "          total += targets.size(0)\n",
        "          correct += predicted.eq(targets).sum().item()\n",
        "      acc = 100.*correct/total\n",
        "      epoch_train_loss = train_loss/total\n",
        "      self.train_losses.append(epoch_train_loss)\n",
        "      self.train_accuracy.append(acc)\n",
        "\n",
        "      # validation\n",
        "      self.model.eval()\n",
        "      validation_loss = 0\n",
        "      valid_correct = 0\n",
        "      valid_total = 0\n",
        "      with torch.no_grad():\n",
        "          for batch_idx, (inputs, targets) in enumerate(validloader):\n",
        "              inputs, targets = inputs.to(device), targets.to(device)\n",
        "              outputs = net(inputs)\n",
        "              loss = criterion(outputs, targets)\n",
        "\n",
        "              # # L1 regularization\n",
        "              # l1_lambda = 0.001\n",
        "              # l1_norm = sum(torch.linalg.norm(p, 1) for p in self.model.parameters())\n",
        "              # l1 = l1_lambda * l1_norm\n",
        "              # validation_loss += (loss.item() + l1)\n",
        "\n",
        "              validation_loss += loss.item()\n",
        "              _, predicted = outputs.max(1)\n",
        "              valid_total += targets.size(0)\n",
        "              valid_correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "      val_acc = 100.*valid_correct/valid_total\n",
        "      epoch_validation_loss = validation_loss/valid_total\n",
        "    \n",
        "      # early_stop\n",
        "      if (epoch > 1 and epoch_validation_loss > self.val_losses[-1]):\n",
        "            trigger_times += 1\n",
        "            if (trigger_times >= self.patience):\n",
        "              print('Early stopping!')\n",
        "              break\n",
        "      else:\n",
        "        trigger_times = 0\n",
        "      self.val_losses.append(epoch_validation_loss)\n",
        "      self.val_accuracy.append(val_acc)\n",
        "\n",
        "\n",
        "      print(f\"[{epoch}/{self.epochs}] Training Accuracy: {acc:.2f}%\\t Validation Accuracy: {val_acc:.2f}%\")\n",
        "      print(f\"[{epoch}/{self.epochs}] Training loss: {epoch_train_loss:.8f}\\t Validation loss: {epoch_validation_loss:.8f}\")\n",
        "      print('\\n')\n",
        "      #torch.save(self.model.state_dict(), model_path)\n",
        "    \n",
        "  def test(self, testloader):\n",
        "    global best_acc\n",
        "    self.model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "\n",
        "    print(f'test accuracy = {acc}')\n",
        "    if acc > 80.:\n",
        "        print('Saving..')\n",
        "        checkpoint_path = f'/content/drive/MyDrive/DL_Models/ResNet_saved.pkl'\n",
        "        torch.save(self.model.state_dict(), checkpoint_path)\n",
        "        best_acc = acc\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Lihyg8tZYNLB"
      },
      "outputs": [],
      "source": [
        "para = {\n",
        "    'learning_rate':5e-3,\n",
        "    'weight_decay':2e-4,\n",
        "    'max_epochs': 100\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZB75X6LUM0a5"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_candidate = {\n",
        "    'SGD':optim.SGD(net.parameters(), lr=para['learning_rate'],\n",
        "                      momentum=0.9, weight_decay=2e-4),\n",
        "    'AdamW':optim.AdamW(net.parameters(), lr=para['learning_rate'],weight_decay = para['weight_decay'])\n",
        "}\n",
        "optimizer = optimizer_candidate['AdamW']\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Nz-OEuTV3sfT"
      },
      "outputs": [],
      "source": [
        "opt = Optimization(model=net, loss_fn=criterion, optimizer=scheduler, patience = 10, EPOCH = para['max_epochs'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItPL9Cc95rQI",
        "outputId": "f5f8ae10-65df-4a3c-f45b-171a606fb3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/100] Training Accuracy: 34.65%\t Validation Accuracy: 44.41%\n",
            "[1/100] Training loss: 0.01380401\t Validation loss: 0.01172747\n",
            "\n",
            "\n",
            "[2/100] Training Accuracy: 52.96%\t Validation Accuracy: 53.49%\n",
            "[2/100] Training loss: 0.01007632\t Validation loss: 0.01073987\n",
            "\n",
            "\n",
            "[3/100] Training Accuracy: 60.57%\t Validation Accuracy: 63.74%\n",
            "[3/100] Training loss: 0.00860319\t Validation loss: 0.00784090\n",
            "\n",
            "\n",
            "[4/100] Training Accuracy: 64.75%\t Validation Accuracy: 69.02%\n",
            "[4/100] Training loss: 0.00768566\t Validation loss: 0.00676601\n",
            "\n",
            "\n",
            "[5/100] Training Accuracy: 67.99%\t Validation Accuracy: 70.65%\n",
            "[5/100] Training loss: 0.00703284\t Validation loss: 0.00650714\n",
            "\n",
            "\n",
            "[6/100] Training Accuracy: 70.58%\t Validation Accuracy: 70.42%\n",
            "[6/100] Training loss: 0.00646656\t Validation loss: 0.00653656\n",
            "\n",
            "\n",
            "[7/100] Training Accuracy: 73.28%\t Validation Accuracy: 76.10%\n",
            "[7/100] Training loss: 0.00588228\t Validation loss: 0.00533581\n",
            "\n",
            "\n",
            "[8/100] Training Accuracy: 75.66%\t Validation Accuracy: 76.70%\n",
            "[8/100] Training loss: 0.00542585\t Validation loss: 0.00512644\n",
            "\n",
            "\n",
            "[9/100] Training Accuracy: 77.49%\t Validation Accuracy: 78.72%\n",
            "[9/100] Training loss: 0.00501395\t Validation loss: 0.00475061\n",
            "\n",
            "\n",
            "[10/100] Training Accuracy: 78.64%\t Validation Accuracy: 78.56%\n",
            "[10/100] Training loss: 0.00475801\t Validation loss: 0.00470889\n",
            "\n",
            "\n",
            "[11/100] Training Accuracy: 79.95%\t Validation Accuracy: 78.93%\n",
            "[11/100] Training loss: 0.00445281\t Validation loss: 0.00484870\n",
            "\n",
            "\n",
            "[12/100] Training Accuracy: 81.32%\t Validation Accuracy: 81.22%\n",
            "[12/100] Training loss: 0.00420964\t Validation loss: 0.00427578\n",
            "\n",
            "\n",
            "[13/100] Training Accuracy: 81.96%\t Validation Accuracy: 80.33%\n",
            "[13/100] Training loss: 0.00404524\t Validation loss: 0.00442775\n",
            "\n",
            "\n",
            "[14/100] Training Accuracy: 82.90%\t Validation Accuracy: 81.63%\n",
            "[14/100] Training loss: 0.00381115\t Validation loss: 0.00405509\n",
            "\n",
            "\n",
            "[15/100] Training Accuracy: 83.56%\t Validation Accuracy: 80.28%\n",
            "[15/100] Training loss: 0.00366130\t Validation loss: 0.00452481\n",
            "\n",
            "\n",
            "[16/100] Training Accuracy: 84.16%\t Validation Accuracy: 81.76%\n",
            "[16/100] Training loss: 0.00351478\t Validation loss: 0.00423421\n",
            "\n",
            "\n",
            "[17/100] Training Accuracy: 85.20%\t Validation Accuracy: 84.67%\n",
            "[17/100] Training loss: 0.00328649\t Validation loss: 0.00347613\n",
            "\n",
            "\n",
            "[18/100] Training Accuracy: 85.45%\t Validation Accuracy: 84.43%\n",
            "[18/100] Training loss: 0.00319597\t Validation loss: 0.00367644\n",
            "\n",
            "\n",
            "[19/100] Training Accuracy: 86.42%\t Validation Accuracy: 84.82%\n",
            "[19/100] Training loss: 0.00305887\t Validation loss: 0.00343189\n",
            "\n",
            "\n",
            "[20/100] Training Accuracy: 86.72%\t Validation Accuracy: 85.83%\n",
            "[20/100] Training loss: 0.00297183\t Validation loss: 0.00316049\n",
            "\n",
            "\n",
            "[21/100] Training Accuracy: 86.94%\t Validation Accuracy: 85.51%\n",
            "[21/100] Training loss: 0.00290392\t Validation loss: 0.00331371\n",
            "\n",
            "\n",
            "[22/100] Training Accuracy: 87.79%\t Validation Accuracy: 84.75%\n",
            "[22/100] Training loss: 0.00272671\t Validation loss: 0.00377935\n",
            "\n",
            "\n",
            "[23/100] Training Accuracy: 88.37%\t Validation Accuracy: 85.20%\n",
            "[23/100] Training loss: 0.00258668\t Validation loss: 0.00353192\n",
            "\n",
            "\n",
            "[24/100] Training Accuracy: 88.64%\t Validation Accuracy: 86.23%\n",
            "[24/100] Training loss: 0.00254149\t Validation loss: 0.00332019\n",
            "\n",
            "\n",
            "[25/100] Training Accuracy: 88.93%\t Validation Accuracy: 86.83%\n",
            "[25/100] Training loss: 0.00244604\t Validation loss: 0.00316690\n",
            "\n",
            "\n",
            "[26/100] Training Accuracy: 89.09%\t Validation Accuracy: 86.30%\n",
            "[26/100] Training loss: 0.00239048\t Validation loss: 0.00324608\n",
            "\n",
            "\n",
            "[27/100] Training Accuracy: 89.65%\t Validation Accuracy: 85.79%\n",
            "[27/100] Training loss: 0.00227152\t Validation loss: 0.00340462\n",
            "\n",
            "\n",
            "[28/100] Training Accuracy: 90.05%\t Validation Accuracy: 87.03%\n",
            "[28/100] Training loss: 0.00218730\t Validation loss: 0.00309476\n",
            "\n",
            "\n",
            "[29/100] Training Accuracy: 90.33%\t Validation Accuracy: 86.33%\n",
            "[29/100] Training loss: 0.00212569\t Validation loss: 0.00335651\n",
            "\n",
            "\n",
            "[30/100] Training Accuracy: 90.80%\t Validation Accuracy: 86.34%\n",
            "[30/100] Training loss: 0.00205236\t Validation loss: 0.00329300\n",
            "\n",
            "\n",
            "[31/100] Training Accuracy: 90.92%\t Validation Accuracy: 88.04%\n",
            "[31/100] Training loss: 0.00198613\t Validation loss: 0.00296052\n",
            "\n",
            "\n",
            "[32/100] Training Accuracy: 91.17%\t Validation Accuracy: 87.66%\n",
            "[32/100] Training loss: 0.00192198\t Validation loss: 0.00297214\n",
            "\n",
            "\n",
            "[33/100] Training Accuracy: 91.73%\t Validation Accuracy: 87.62%\n",
            "[33/100] Training loss: 0.00183572\t Validation loss: 0.00310069\n",
            "\n",
            "\n",
            "[34/100] Training Accuracy: 91.85%\t Validation Accuracy: 87.14%\n",
            "[34/100] Training loss: 0.00179058\t Validation loss: 0.00319348\n",
            "\n",
            "\n",
            "[35/100] Training Accuracy: 92.18%\t Validation Accuracy: 88.31%\n",
            "[35/100] Training loss: 0.00170572\t Validation loss: 0.00298550\n",
            "\n",
            "\n",
            "[36/100] Training Accuracy: 92.39%\t Validation Accuracy: 87.70%\n",
            "[36/100] Training loss: 0.00166569\t Validation loss: 0.00301892\n",
            "\n",
            "\n",
            "[37/100] Training Accuracy: 92.46%\t Validation Accuracy: 87.63%\n",
            "[37/100] Training loss: 0.00162028\t Validation loss: 0.00313543\n",
            "\n",
            "\n",
            "[38/100] Training Accuracy: 92.86%\t Validation Accuracy: 88.66%\n",
            "[38/100] Training loss: 0.00157489\t Validation loss: 0.00286511\n",
            "\n",
            "\n",
            "[39/100] Training Accuracy: 93.03%\t Validation Accuracy: 88.59%\n",
            "[39/100] Training loss: 0.00151663\t Validation loss: 0.00304201\n",
            "\n",
            "\n",
            "[40/100] Training Accuracy: 93.30%\t Validation Accuracy: 88.74%\n",
            "[40/100] Training loss: 0.00148483\t Validation loss: 0.00283455\n",
            "\n",
            "\n",
            "[41/100] Training Accuracy: 93.35%\t Validation Accuracy: 87.19%\n",
            "[41/100] Training loss: 0.00142431\t Validation loss: 0.00343180\n",
            "\n",
            "\n",
            "[42/100] Training Accuracy: 93.59%\t Validation Accuracy: 88.40%\n",
            "[42/100] Training loss: 0.00140839\t Validation loss: 0.00306122\n",
            "\n",
            "\n",
            "[43/100] Training Accuracy: 93.70%\t Validation Accuracy: 87.66%\n",
            "[43/100] Training loss: 0.00137484\t Validation loss: 0.00312959\n",
            "\n",
            "\n",
            "[44/100] Training Accuracy: 94.18%\t Validation Accuracy: 88.97%\n",
            "[44/100] Training loss: 0.00129883\t Validation loss: 0.00288614\n",
            "\n",
            "\n",
            "[45/100] Training Accuracy: 94.11%\t Validation Accuracy: 88.91%\n",
            "[45/100] Training loss: 0.00129617\t Validation loss: 0.00292061\n",
            "\n",
            "\n",
            "[46/100] Training Accuracy: 94.20%\t Validation Accuracy: 88.19%\n",
            "[46/100] Training loss: 0.00125549\t Validation loss: 0.00333719\n",
            "\n",
            "\n",
            "[47/100] Training Accuracy: 94.52%\t Validation Accuracy: 89.08%\n",
            "[47/100] Training loss: 0.00119741\t Validation loss: 0.00291638\n",
            "\n",
            "\n",
            "[48/100] Training Accuracy: 94.70%\t Validation Accuracy: 87.96%\n",
            "[48/100] Training loss: 0.00117995\t Validation loss: 0.00326437\n",
            "\n",
            "\n",
            "[49/100] Training Accuracy: 94.65%\t Validation Accuracy: 88.40%\n",
            "[49/100] Training loss: 0.00116824\t Validation loss: 0.00314274\n",
            "\n",
            "\n",
            "[50/100] Training Accuracy: 94.86%\t Validation Accuracy: 86.54%\n",
            "[50/100] Training loss: 0.00113660\t Validation loss: 0.00373193\n",
            "\n",
            "\n",
            "[51/100] Training Accuracy: 95.06%\t Validation Accuracy: 89.37%\n",
            "[51/100] Training loss: 0.00109051\t Validation loss: 0.00291727\n",
            "\n",
            "\n",
            "[52/100] Training Accuracy: 95.07%\t Validation Accuracy: 88.75%\n",
            "[52/100] Training loss: 0.00107164\t Validation loss: 0.00321187\n",
            "\n",
            "\n",
            "[53/100] Training Accuracy: 95.39%\t Validation Accuracy: 88.52%\n",
            "[53/100] Training loss: 0.00102840\t Validation loss: 0.00317332\n",
            "\n",
            "\n",
            "[54/100] Training Accuracy: 95.35%\t Validation Accuracy: 88.79%\n",
            "[54/100] Training loss: 0.00101131\t Validation loss: 0.00327630\n",
            "\n",
            "\n",
            "[55/100] Training Accuracy: 95.55%\t Validation Accuracy: 89.16%\n",
            "[55/100] Training loss: 0.00097584\t Validation loss: 0.00311447\n",
            "\n",
            "\n",
            "[56/100] Training Accuracy: 95.55%\t Validation Accuracy: 89.60%\n",
            "[56/100] Training loss: 0.00094848\t Validation loss: 0.00298440\n",
            "\n",
            "\n",
            "[57/100] Training Accuracy: 95.60%\t Validation Accuracy: 89.02%\n",
            "[57/100] Training loss: 0.00094192\t Validation loss: 0.00322436\n",
            "\n",
            "\n",
            "[58/100] Training Accuracy: 95.78%\t Validation Accuracy: 88.98%\n",
            "[58/100] Training loss: 0.00093105\t Validation loss: 0.00324018\n",
            "\n",
            "\n",
            "[59/100] Training Accuracy: 95.99%\t Validation Accuracy: 89.57%\n",
            "[59/100] Training loss: 0.00087811\t Validation loss: 0.00315180\n",
            "\n",
            "\n",
            "[60/100] Training Accuracy: 95.91%\t Validation Accuracy: 88.75%\n",
            "[60/100] Training loss: 0.00088202\t Validation loss: 0.00345180\n",
            "\n",
            "\n",
            "[61/100] Training Accuracy: 96.13%\t Validation Accuracy: 88.89%\n",
            "[61/100] Training loss: 0.00086193\t Validation loss: 0.00338660\n",
            "\n",
            "\n",
            "[62/100] Training Accuracy: 96.15%\t Validation Accuracy: 88.73%\n",
            "[62/100] Training loss: 0.00085123\t Validation loss: 0.00347350\n",
            "\n",
            "\n",
            "[63/100] Training Accuracy: 96.06%\t Validation Accuracy: 88.59%\n",
            "[63/100] Training loss: 0.00084565\t Validation loss: 0.00350148\n",
            "\n",
            "\n",
            "[64/100] Training Accuracy: 96.22%\t Validation Accuracy: 88.66%\n",
            "[64/100] Training loss: 0.00084761\t Validation loss: 0.00348462\n",
            "\n",
            "\n",
            "[65/100] Training Accuracy: 96.44%\t Validation Accuracy: 89.49%\n",
            "[65/100] Training loss: 0.00078676\t Validation loss: 0.00325836\n",
            "\n",
            "\n",
            "[66/100] Training Accuracy: 96.55%\t Validation Accuracy: 89.17%\n",
            "[66/100] Training loss: 0.00075084\t Validation loss: 0.00332250\n",
            "\n",
            "\n",
            "[67/100] Training Accuracy: 96.19%\t Validation Accuracy: 88.58%\n",
            "[67/100] Training loss: 0.00082302\t Validation loss: 0.00356275\n",
            "\n",
            "\n",
            "[68/100] Training Accuracy: 96.13%\t Validation Accuracy: 89.64%\n",
            "[68/100] Training loss: 0.00082680\t Validation loss: 0.00316380\n",
            "\n",
            "\n",
            "[69/100] Training Accuracy: 96.71%\t Validation Accuracy: 88.85%\n",
            "[69/100] Training loss: 0.00071526\t Validation loss: 0.00353160\n",
            "\n",
            "\n",
            "[70/100] Training Accuracy: 96.66%\t Validation Accuracy: 89.90%\n",
            "[70/100] Training loss: 0.00072654\t Validation loss: 0.00351378\n",
            "\n",
            "\n",
            "[71/100] Training Accuracy: 96.81%\t Validation Accuracy: 89.12%\n",
            "[71/100] Training loss: 0.00069861\t Validation loss: 0.00341632\n",
            "\n",
            "\n",
            "[72/100] Training Accuracy: 96.92%\t Validation Accuracy: 88.59%\n",
            "[72/100] Training loss: 0.00067433\t Validation loss: 0.00387735\n",
            "\n",
            "\n",
            "[73/100] Training Accuracy: 96.74%\t Validation Accuracy: 89.39%\n",
            "[73/100] Training loss: 0.00072553\t Validation loss: 0.00356687\n",
            "\n",
            "\n",
            "[74/100] Training Accuracy: 96.97%\t Validation Accuracy: 89.55%\n",
            "[74/100] Training loss: 0.00065925\t Validation loss: 0.00324004\n",
            "\n",
            "\n",
            "[75/100] Training Accuracy: 96.83%\t Validation Accuracy: 88.90%\n",
            "[75/100] Training loss: 0.00067541\t Validation loss: 0.00360401\n",
            "\n",
            "\n",
            "[76/100] Training Accuracy: 97.04%\t Validation Accuracy: 89.45%\n",
            "[76/100] Training loss: 0.00066855\t Validation loss: 0.00353550\n",
            "\n",
            "\n",
            "[77/100] Training Accuracy: 96.95%\t Validation Accuracy: 89.49%\n",
            "[77/100] Training loss: 0.00067764\t Validation loss: 0.00357595\n",
            "\n",
            "\n",
            "[78/100] Training Accuracy: 97.10%\t Validation Accuracy: 89.48%\n",
            "[78/100] Training loss: 0.00062899\t Validation loss: 0.00344629\n",
            "\n",
            "\n",
            "[79/100] Training Accuracy: 97.28%\t Validation Accuracy: 89.43%\n",
            "[79/100] Training loss: 0.00061035\t Validation loss: 0.00367550\n",
            "\n",
            "\n",
            "[80/100] Training Accuracy: 96.92%\t Validation Accuracy: 89.08%\n",
            "[80/100] Training loss: 0.00066889\t Validation loss: 0.00364521\n",
            "\n",
            "\n",
            "[81/100] Training Accuracy: 97.25%\t Validation Accuracy: 89.18%\n",
            "[81/100] Training loss: 0.00060656\t Validation loss: 0.00363653\n",
            "\n",
            "\n",
            "[82/100] Training Accuracy: 97.22%\t Validation Accuracy: 88.62%\n",
            "[82/100] Training loss: 0.00062013\t Validation loss: 0.00381727\n",
            "\n",
            "\n",
            "[83/100] Training Accuracy: 97.04%\t Validation Accuracy: 89.39%\n",
            "[83/100] Training loss: 0.00063450\t Validation loss: 0.00359820\n",
            "\n",
            "\n",
            "[84/100] Training Accuracy: 97.36%\t Validation Accuracy: 89.30%\n",
            "[84/100] Training loss: 0.00056270\t Validation loss: 0.00369833\n",
            "\n",
            "\n",
            "[85/100] Training Accuracy: 97.46%\t Validation Accuracy: 89.90%\n",
            "[85/100] Training loss: 0.00057607\t Validation loss: 0.00336998\n",
            "\n",
            "\n",
            "[86/100] Training Accuracy: 97.47%\t Validation Accuracy: 89.70%\n",
            "[86/100] Training loss: 0.00055627\t Validation loss: 0.00356231\n",
            "\n",
            "\n",
            "[87/100] Training Accuracy: 97.29%\t Validation Accuracy: 89.22%\n",
            "[87/100] Training loss: 0.00059291\t Validation loss: 0.00368299\n",
            "\n",
            "\n",
            "[88/100] Training Accuracy: 97.40%\t Validation Accuracy: 89.14%\n",
            "[88/100] Training loss: 0.00057563\t Validation loss: 0.00367796\n",
            "\n",
            "\n",
            "[89/100] Training Accuracy: 97.70%\t Validation Accuracy: 89.35%\n",
            "[89/100] Training loss: 0.00052408\t Validation loss: 0.00373394\n",
            "\n",
            "\n",
            "[90/100] Training Accuracy: 97.54%\t Validation Accuracy: 89.40%\n",
            "[90/100] Training loss: 0.00054298\t Validation loss: 0.00391757\n",
            "\n",
            "\n",
            "[91/100] Training Accuracy: 97.57%\t Validation Accuracy: 89.64%\n",
            "[91/100] Training loss: 0.00054762\t Validation loss: 0.00376870\n",
            "\n",
            "\n",
            "[92/100] Training Accuracy: 97.51%\t Validation Accuracy: 89.51%\n",
            "[92/100] Training loss: 0.00056435\t Validation loss: 0.00346890\n",
            "\n",
            "\n",
            "[93/100] Training Accuracy: 97.64%\t Validation Accuracy: 89.45%\n",
            "[93/100] Training loss: 0.00051494\t Validation loss: 0.00370234\n",
            "\n",
            "\n",
            "[94/100] Training Accuracy: 97.50%\t Validation Accuracy: 90.06%\n",
            "[94/100] Training loss: 0.00055333\t Validation loss: 0.00341308\n",
            "\n",
            "\n",
            "[95/100] Training Accuracy: 97.71%\t Validation Accuracy: 89.71%\n",
            "[95/100] Training loss: 0.00050050\t Validation loss: 0.00393401\n",
            "\n",
            "\n",
            "[96/100] Training Accuracy: 97.68%\t Validation Accuracy: 89.64%\n",
            "[96/100] Training loss: 0.00052192\t Validation loss: 0.00362801\n",
            "\n",
            "\n",
            "[97/100] Training Accuracy: 97.77%\t Validation Accuracy: 89.82%\n",
            "[97/100] Training loss: 0.00049794\t Validation loss: 0.00359662\n",
            "\n",
            "\n",
            "[98/100] Training Accuracy: 97.62%\t Validation Accuracy: 90.02%\n",
            "[98/100] Training loss: 0.00052769\t Validation loss: 0.00363912\n",
            "\n",
            "\n",
            "[99/100] Training Accuracy: 97.76%\t Validation Accuracy: 89.26%\n",
            "[99/100] Training loss: 0.00049399\t Validation loss: 0.00377608\n",
            "\n",
            "\n",
            "[100/100] Training Accuracy: 97.76%\t Validation Accuracy: 89.80%\n",
            "[100/100] Training loss: 0.00049293\t Validation loss: 0.00355553\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "opt.train(trainloader, \n",
        "          validloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dIR--fqsB5xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7116c0d1-5518-4688-b421-3a8a9a291fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy = 90.00400641025641\n",
            "Saving..\n"
          ]
        }
      ],
      "source": [
        "opt.test(testloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK_W_xRW2zjY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}